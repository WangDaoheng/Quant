# -*- coding: utf-8 -*-
"""
Tushareæ•°æ®ä¸‹è½½å™¨ - ä¼˜åŒ–ç‰ˆ
åŒ¹é…æœ€æ–°è¡¨ç»“æ„ï¼ˆKçº¿è¡¨åä¿æŒä¸å˜ï¼‰
"""

import tushare as ts
import pandas as pd
import sys
import time
import logging
import warnings
from datetime import datetime, timedelta
import traceback
from tqdm import tqdm

import CommonProperties.Base_Properties as base_properties
import CommonProperties.Mysql_Utils as mysql_utils
from CommonProperties.DateUtility import DateUtility

warnings.filterwarnings('ignore', category=FutureWarning)


class TushareDataFetcher:
    """Tushareæ•°æ®ä¸‹è½½å™¨ - åŒ¹é…æœ€æ–°è¡¨ç»“æ„ï¼ˆKçº¿è¡¨åä¿æŒä¸å˜ï¼‰"""

    def __init__(self, stock_code_df=None):
        """
        åˆå§‹åŒ–Tushare
        :param stock_code_df: è‚¡ç¥¨ä»£ç DataFrameï¼Œå¯é€‰
        """
        # è®¾ç½®Tushare Token
        ts.set_token(base_properties.ts_token)
        self.pro = ts.pro_api()
        self.stock_code_df = stock_code_df

        # APIé¢‘ç‡æ§åˆ¶é…ç½®ï¼ˆ10000ç§¯åˆ†è´¦å·ä¼˜åŒ–ï¼‰
        self.api_delay = {
            'kline': 0.2,  # Kçº¿æ•°æ®ï¼ˆç›¸å¯¹å®½æ¾ï¼‰
            'normal': 0.3,  # æ™®é€šæ¿å—æ¥å£
            'member': 0.5,  # æˆåˆ†è‚¡æ¥å£ï¼ˆä¸¥æ ¼é™åˆ¶ï¼‰
            'error': 2.0,
            'batch': 3.0  # æ‰¹æ¬¡é—´å»¶è¿Ÿ
        }

        # æ—¥å¿—é…ç½®
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.StreamHandler(),
                logging.FileHandler(f'tushare_downloader_{DateUtility.today()}.log')
            ]
        )
        self.logger = logging.getLogger(__name__)

    # ============ åŸæœ‰çš„æ—¥Kçº¿ä¸‹è½½åŠŸèƒ½ ============

    def get_stock_kline_tushare(self):
        """
        ä½¿ç”¨Tushareè·å–å…¨éƒ¨è‚¡ç¥¨çš„å†å²æ—¥Kçº¿æ•°æ®
        """
        self.logger.info("å¼€å§‹è·å–è‚¡ç¥¨æ—¥Kçº¿æ•°æ®")

        # 1. è·å–æ—¥æœŸèŒƒå›´
        today = DateUtility.today()

        if int(today[6:8]) > 15:
            time_start_date = DateUtility.next_day(-15)  # 15å¤©å‰
        else:
            time_start_date = DateUtility.first_day_of_month()  # å½“æœˆ1å·
        time_end_date = today

        # 2. è·å–è‚¡ç¥¨ä»£ç åˆ—è¡¨
        stock_code_list = mysql_utils.get_stock_codes_latest(self.stock_code_df)
        if not stock_code_list:
            self.logger.warning("è‚¡ç¥¨ä»£ç åˆ—è¡¨ä¸ºç©º")
            return pd.DataFrame()

        self.logger.info(
            f"å°†è·å– {len(stock_code_list)} åªè‚¡ç¥¨çš„Kçº¿æ•°æ®ï¼Œæ—¥æœŸèŒƒå›´: {time_start_date} åˆ° {time_end_date}")

        # 3. åˆ†æ‰¹å¤„ç†è®¾ç½®
        batch_size = 100
        total_batches = (len(stock_code_list) + batch_size - 1) // batch_size
        kline_total_df = pd.DataFrame()

        # 4. åˆ†æ‰¹è·å–Kçº¿æ•°æ®
        for i in range(0, len(stock_code_list), batch_size):
            batch_list = stock_code_list[i:i + batch_size]
            batch_num = i // batch_size + 1

            sys.stdout.write(f"\rå½“å‰æ‰§è¡ŒKçº¿æ•°æ®çš„ç¬¬{batch_num}æ‰¹æ¬¡ï¼Œæ€»å…±{total_batches}ä¸ªæ‰¹æ¬¡")
            sys.stdout.flush()

            # å¾ªç¯å•ä¸ªè‚¡ç¥¨è°ƒç”¨
            for ts_code in batch_list:
                try:
                    df_batch = ts.pro_bar(
                        ts_code=ts_code,
                        start_date=time_start_date,
                        end_date=time_end_date,
                        adj='qfq',  # å‰å¤æƒ
                        freq='D'  # æ—¥çº¿
                    )

                    if df_batch is not None and not df_batch.empty:
                        kline_total_df = pd.concat([kline_total_df, df_batch], ignore_index=True)

                    # é¢‘ç‡æ§åˆ¶
                    time.sleep(self.api_delay['kline'])

                except Exception as e:
                    self.logger.warning(f"è‚¡ç¥¨ {ts_code} Kçº¿è·å–å¤±è´¥: {str(e)[:50]}")
                    time.sleep(self.api_delay['error'])
                    continue

            # æ‰¹æ¬¡é—´å»¶è¿Ÿ
            if i + batch_size < len(stock_code_list):
                time.sleep(1)

        sys.stdout.write("\n")

        # 5. æ•°æ®å¤„ç† - åŒ¹é…è¡¨ç»“æ„
        if not kline_total_df.empty:
            # é‡å‘½ååˆ—ä»¥åŒ¹é…è¡¨ç»“æ„
            kline_total_df.rename(columns={
                'ts_code': 'stock_code',
                'trade_date': 'ymd',
                'pct_chg': 'change_pct',
                'vol': 'volume',
                'amount': 'trading_amount'
            }, inplace=True)

            # è½¬æ¢æ—¥æœŸæ ¼å¼ä¸ºYYYYMMDDå­—ç¬¦ä¸²
            kline_total_df['ymd'] = pd.to_datetime(kline_total_df['ymd']).dt.strftime('%Y%m%d')

            # ç¡®ä¿æ•°æ®ç±»å‹æ­£ç¡®
            numeric_columns = ['open', 'close', 'high', 'low', 'change_pct', 'volume', 'trading_amount']
            for col in numeric_columns:
                if col in kline_total_df.columns:
                    kline_total_df[col] = pd.to_numeric(kline_total_df[col], errors='coerce')

            # é€‰æ‹©éœ€è¦çš„åˆ—ï¼Œå®Œå…¨åŒ¹é…è¡¨ç»“æ„
            required_columns = ['ymd', 'stock_code', 'open', 'close', 'high', 'low',
                                'change_pct', 'volume', 'trading_amount']

            # ç¡®ä¿æ‰€æœ‰å¿…éœ€çš„åˆ—éƒ½å­˜åœ¨
            for col in required_columns:
                if col not in kline_total_df.columns:
                    kline_total_df[col] = None

            kline_total_df = kline_total_df[required_columns]

            # å»é™¤é‡å¤
            kline_total_df = kline_total_df.drop_duplicates(subset=['ymd', 'stock_code'], keep='first')

            self.logger.info(f"æˆåŠŸè·å– {len(kline_total_df)} æ¡æ—¥Kçº¿æ•°æ®")
            return kline_total_df
        else:
            self.logger.warning('Kçº¿æ•°æ®è·å–ä¸ºç©º')
            return pd.DataFrame()

    def save_kline_to_mysql(self, df=None):
        """
        ä¿å­˜Kçº¿æ•°æ®åˆ°MySQL - ä¿æŒåŸè¡¨å
        :param df: Kçº¿DataFrameï¼Œå¦‚ä¸ºNoneåˆ™é‡æ–°è·å–
        """
        if df is None:
            df = self.get_stock_kline_tushare()

        if df.empty:
            self.logger.warning("Kçº¿æ•°æ®ä¸ºç©ºï¼Œä¸ä¿å­˜åˆ°æ•°æ®åº“")
            return False

        try:
            mysql_utils.data_from_dataframe_to_mysql(
                user=base_properties.origin_mysql_user,
                password=base_properties.origin_mysql_password,
                host=base_properties.origin_mysql_host,
                database=base_properties.origin_mysql_database,
                df=df,
                table_name="ods_stock_kline_daily_ts",  # ä¿æŒåŸè¡¨åä¸å˜
                merge_on=['ymd', 'stock_code']
            )
            self.logger.info(f"Kçº¿æ•°æ®æˆåŠŸä¿å­˜åˆ°æ•°æ®åº“: {len(df)} æ¡è®°å½•")
            return True
        except Exception as e:
            self.logger.error(f"Kçº¿æ•°æ®ä¿å­˜åˆ°MySQLå¤±è´¥: {e}")
            return False

    # ============ æ–°å¢çš„6ä¸ªæ¿å—æ•°æ®æ¥å£ ============

    def _safe_api_call(self, api_func, *args, **kwargs):
        """å®‰å…¨è°ƒç”¨APIï¼Œå¸¦é¢‘ç‡æ§åˆ¶å’Œé‡è¯•"""
        max_retries = 3
        for attempt in range(max_retries):
            try:
                result = api_func(*args, **kwargs)
                return result
            except Exception as e:
                error_msg = str(e)
                if "é¢‘ç¹" in error_msg or "limit" in error_msg.lower() or "429" in error_msg:
                    wait_time = 5 * (attempt + 1)
                    self.logger.warning(f"APIé™æµï¼Œç­‰å¾…{wait_time}ç§’åé‡è¯•...")
                    time.sleep(wait_time)
                    continue
                elif "ç§¯åˆ†ä¸å¤Ÿ" in error_msg or "permission" in error_msg.lower():
                    self.logger.error(f"ç§¯åˆ†ä¸è¶³æˆ–æƒé™ä¸å¤Ÿ: {error_msg}")
                    return None
                elif attempt < max_retries - 1:
                    self.logger.warning(f"APIè°ƒç”¨å¤±è´¥ï¼Œç¬¬{attempt + 1}æ¬¡é‡è¯•: {error_msg[:50]}")
                    time.sleep(self.api_delay['error'])
                    continue
                else:
                    self.logger.error(f"APIè°ƒç”¨æœ€ç»ˆå¤±è´¥: {error_msg}")
                    return None
        return None

    # ===== åŒèŠ±é¡ºæ¿å—æ•°æ®æ¥å£ =====

    def get_ths_index(self, exchange='A', index_type=None):
        """åŒèŠ±é¡ºæ¿å—æŒ‡æ•°åˆ—è¡¨ - åŒ¹é…æ–°è¡¨ç»“æ„"""
        try:
            self.logger.info("è·å–åŒèŠ±é¡ºæ¿å—æŒ‡æ•°åˆ—è¡¨...")
            params = {'exchange': exchange}
            if index_type:
                params['type'] = index_type

            df = self._safe_api_call(self.pro.ths_index, **params)
            time.sleep(self.api_delay['normal'])

            if df is not None and not df.empty:
                # æ·»åŠ æ ¸å¿ƒæ—¥æœŸç»´åº¦
                df['ymd'] = DateUtility.today()

                # æ—¥æœŸæ ¼å¼è½¬æ¢
                if 'list_date' in df.columns:
                    df['list_date'] = pd.to_datetime(df['list_date'], format='%Y%m%d', errors='coerce').dt.strftime(
                        '%Y%m%d')

                # é‡å‘½ååˆ—ä»¥åŒ¹é…æ–°è¡¨ç»“æ„
                df = df.rename(columns={
                    'ts_code': 'board_code',
                    'name': 'board_name',
                    'count': 'component_count',
                    'exchange': 'market'
                })

                # ç¡®ä¿æ‰€æœ‰å¿…éœ€çš„åˆ—éƒ½å­˜åœ¨
                required_columns = ['ymd', 'board_name', 'board_code', 'component_count',
                                    'market', 'list_date', 'index_type']

                for col in required_columns:
                    if col not in df.columns:
                        if col == 'index_type' and 'type' in df.columns:
                            df['index_type'] = df['type']
                        elif col == 'index_type':
                            df['index_type'] = 'N'  # é»˜è®¤å€¼
                        else:
                            df[col] = None

                # è½¬æ¢æ•°å€¼ç±»å‹
                if 'component_count' in df.columns:
                    df['component_count'] = pd.to_numeric(df['component_count'], errors='coerce').astype('Int64')

                return df[required_columns]

            return pd.DataFrame()

        except Exception as e:
            self.logger.error(f"è·å–ths_indexå¤±è´¥: {e}")
            return pd.DataFrame()

    def get_ths_daily(self, ts_code=None, start_date=None, end_date=None, limit_days=30):
        """åŒèŠ±é¡ºæ¿å—æŒ‡æ•°è¡Œæƒ… - åŒ¹é…æ–°è¡¨ç»“æ„"""
        try:
            if not end_date:
                end_date = DateUtility.today()
            if not start_date:
                start_date = (datetime.strptime(end_date, '%Y%m%d') -
                              timedelta(days=limit_days)).strftime('%Y%m%d')

            self.logger.info(f"è·å–åŒèŠ±é¡ºæ¿å—è¡Œæƒ… {start_date}-{end_date}")

            params = {'start_date': start_date, 'end_date': end_date}
            if ts_code:
                params['ts_code'] = ts_code

            df = self._safe_api_call(self.pro.ths_daily, **params)
            time.sleep(self.api_delay['normal'])

            if df is not None and not df.empty:
                # è½¬æ¢æ—¥æœŸæ ¼å¼
                df['trade_date'] = pd.to_datetime(df['trade_date'], format='%Y%m%d').dt.strftime('%Y%m%d')

                # è·å–æ¿å—åç§°ä¿¡æ¯
                board_info = {}
                if 'ts_code' in df.columns:
                    unique_codes = df['ts_code'].unique()
                    for code in unique_codes:
                        # è¿™é‡Œéœ€è¦æ ¹æ®å®é™…æƒ…å†µè·å–æ¿å—åç§°ï¼Œæš‚æ—¶ç”¨ä»£ç æ›¿ä»£
                        board_info[code] = code

                # é‡å‘½ååˆ—ä»¥åŒ¹é…æ–°è¡¨ç»“æ„
                df = df.rename(columns={
                    'ts_code': 'board_code',
                    'trade_date': 'ymd',
                    'pre_close': 'prev_close',
                    'change': 'change_amt',
                    'pct_change': 'change_pct',
                    'vol': 'trading_volume',
                    'amount': 'avg_price',  # æ³¨æ„ï¼šåŸæ¥å£amountå­—æ®µå¯¹åº”è¡¨ç»“æ„ä¸­çš„avg_price
                    'total_mv': 'total_market_value',
                    'float_mv': 'float_market_value',
                    'turnover_rate': 'turnover_rate'
                })

                # æ·»åŠ æ¿å—åç§°
                df['board_name'] = df['board_code'].map(board_info)

                # ç¡®ä¿æ‰€æœ‰å¿…éœ€çš„åˆ—éƒ½å­˜åœ¨
                required_columns = ['ymd', 'board_name', 'board_code', 'open', 'high', 'low',
                                    'close', 'prev_close', 'avg_price', 'change_amt', 'change_pct',
                                    'trading_volume', 'turnover_rate', 'total_market_value', 'float_market_value']

                for col in required_columns:
                    if col not in df.columns:
                        df[col] = None

                # è½¬æ¢æ•°å€¼ç±»å‹
                numeric_columns = ['open', 'high', 'low', 'close', 'prev_close', 'avg_price',
                                   'change_amt', 'change_pct', 'trading_volume', 'turnover_rate',
                                   'total_market_value', 'float_market_value']
                for col in numeric_columns:
                    if col in df.columns:
                        df[col] = pd.to_numeric(df[col], errors='coerce')

                return df[required_columns]

            return pd.DataFrame()

        except Exception as e:
            self.logger.error(f"è·å–ths_dailyå¤±è´¥: {e}")
            return pd.DataFrame()

    def get_ths_member(self, ts_code):
        """åŒèŠ±é¡ºæ¿å—æˆåˆ†è‚¡ - åŒ¹é…æ–°è¡¨ç»“æ„"""
        try:
            self.logger.info(f"è·å–æ¿å—æˆåˆ†è‚¡: {ts_code}")

            df = self._safe_api_call(self.pro.ths_member, ts_code=ts_code)
            time.sleep(self.api_delay['member'])

            if df is not None and not df.empty:
                # æ·»åŠ æ ¸å¿ƒæ—¥æœŸç»´åº¦å’Œæ¿å—ä¿¡æ¯
                df['ymd'] = DateUtility.today()
                df['board_code'] = ts_code

                # è·å–æ¿å—åç§°ï¼ˆè¿™é‡Œéœ€è¦æ ¹æ®å®é™…æƒ…å†µè¡¥å……ï¼‰
                df['board_name'] = ts_code  # ä¸´æ—¶ç”¨ä»£ç ä»£æ›¿ï¼Œå®é™…åº”ä»ths_indexè·å–

                # é‡å‘½ååˆ—ä»¥åŒ¹é…æ–°è¡¨ç»“æ„
                df = df.rename(columns={
                    'con_code': 'stock_code',
                    'con_name': 'stock_name',
                    'is_new': 'is_new',
                    'weight': 'weight'
                })

                # æ—¥æœŸæ ¼å¼è½¬æ¢
                if 'in_date' in df.columns:
                    df['in_date'] = pd.to_datetime(df['in_date'], errors='coerce').dt.strftime('%Y%m%d')
                if 'out_date' in df.columns:
                    df['out_date'] = pd.to_datetime(df['out_date'], errors='coerce').dt.strftime('%Y%m%d')

                # ç¡®ä¿æ‰€æœ‰å¿…éœ€çš„åˆ—éƒ½å­˜åœ¨
                required_columns = ['ymd', 'board_name', 'board_code', 'stock_code',
                                    'stock_name', 'weight', 'in_date', 'out_date', 'is_new']

                for col in required_columns:
                    if col not in df.columns:
                        df[col] = None

                # è½¬æ¢æ•°å€¼ç±»å‹
                if 'weight' in df.columns:
                    df['weight'] = pd.to_numeric(df['weight'], errors='coerce')

                return df[required_columns]

            return pd.DataFrame()

        except Exception as e:
            self.logger.error(f"è·å–ths_member({ts_code})å¤±è´¥: {e}")
            return pd.DataFrame()

    # ===== ä¸œæ–¹è´¢å¯Œæ¿å—æ•°æ®æ¥å£ =====

    def get_dc_index(self, trade_date=None, ts_code=None):
        """ä¸œæ–¹è´¢å¯Œæ¦‚å¿µæ¿å— - åŒ¹é…æ–°è¡¨ç»“æ„"""
        try:
            if not trade_date:
                trade_date = DateUtility.today()

            self.logger.info(f"è·å–ä¸œæ–¹è´¢å¯Œæ¦‚å¿µæ¿å— {trade_date}")

            params = {'trade_date': trade_date}
            if ts_code:
                params['ts_code'] = ts_code

            df = self._safe_api_call(self.pro.dc_index, **params)
            time.sleep(self.api_delay['normal'])

            if df is not None and not df.empty:
                # æ·»åŠ æ—¥æœŸç»´åº¦
                df['ymd'] = trade_date

                # é‡å‘½ååˆ—ä»¥åŒ¹é…æ–°è¡¨ç»“æ„
                df = df.rename(columns={
                    'ts_code': 'board_code',
                    'name': 'board_name',
                    'leading': 'leading_stock',
                    'leading_code': 'leading_stock_code',
                    'pct_change': 'change_pct',
                    'leading_pct': 'leading_stock_pct',
                    'total_mv': 'total_market_value',
                    'up_num': 'rising_stocks_num',
                    'down_num': 'falling_stocks_num',
                    'turnover_rate': 'turnover_rate'
                })

                # ç¡®ä¿æ‰€æœ‰å¿…éœ€çš„åˆ—éƒ½å­˜åœ¨
                required_columns = ['ymd', 'board_name', 'board_code', 'leading_stock',
                                    'leading_stock_code', 'change_pct', 'leading_stock_pct',
                                    'total_market_value', 'turnover_rate', 'rising_stocks_num',
                                    'falling_stocks_num']

                for col in required_columns:
                    if col not in df.columns:
                        df[col] = None

                # è½¬æ¢æ•°å€¼ç±»å‹
                numeric_columns = ['change_pct', 'leading_stock_pct', 'total_market_value',
                                   'turnover_rate', 'rising_stocks_num', 'falling_stocks_num']
                for col in numeric_columns:
                    if col in df.columns:
                        if col in ['rising_stocks_num', 'falling_stocks_num']:
                            df[col] = pd.to_numeric(df[col], errors='coerce').astype('Int64')
                        else:
                            df[col] = pd.to_numeric(df[col], errors='coerce')

                return df[required_columns]

            return pd.DataFrame()

        except Exception as e:
            self.logger.error(f"è·å–dc_indexå¤±è´¥: {e}")
            return pd.DataFrame()

    def get_dc_daily(self, trade_date=None):
        """ä¸œæ–¹è´¢å¯Œæ¿å—è¡Œæƒ… - åŒ¹é…æ–°è¡¨ç»“æ„"""
        try:
            if not trade_date:
                trade_date = DateUtility.today()

            self.logger.info(f"è·å–ä¸œæ–¹è´¢å¯Œæ¿å—è¡Œæƒ… {trade_date}")

            df = self._safe_api_call(self.pro.dc_daily, trade_date=trade_date)
            time.sleep(self.api_delay['normal'])

            if df is not None and not df.empty:
                # æ·»åŠ æ—¥æœŸç»´åº¦
                df['ymd'] = trade_date

                # è·å–æ¿å—åç§°ä¿¡æ¯
                board_info = {}
                if 'ts_code' in df.columns:
                    unique_codes = df['ts_code'].unique()
                    for code in unique_codes:
                        board_info[code] = code  # ä¸´æ—¶ç”¨ä»£ç ä»£æ›¿

                # é‡å‘½ååˆ—ä»¥åŒ¹é…æ–°è¡¨ç»“æ„
                df = df.rename(columns={
                    'ts_code': 'board_code',
                    'change': 'change_amt',
                    'pct_change': 'change_pct',
                    'vol': 'trading_volume',
                    'amount': 'trading_amount',
                    'swing': 'amplitude',
                    'turnover_rate': 'turnover_rate'
                })

                # æ·»åŠ æ¿å—åç§°
                df['board_name'] = df['board_code'].map(board_info)

                # ç¡®ä¿æ‰€æœ‰å¿…éœ€çš„åˆ—éƒ½å­˜åœ¨
                required_columns = ['ymd', 'board_name', 'board_code', 'open', 'high', 'low',
                                    'close', 'change_amt', 'change_pct', 'trading_volume',
                                    'trading_amount', 'amplitude', 'turnover_rate', 'category']

                for col in required_columns:
                    if col not in df.columns:
                        if col == 'category':
                            df['category'] = 'æ¦‚å¿µæ¿å—'  # é»˜è®¤å€¼
                        else:
                            df[col] = None

                # è½¬æ¢æ•°å€¼ç±»å‹
                numeric_columns = ['open', 'high', 'low', 'close', 'change_amt', 'change_pct',
                                   'trading_volume', 'trading_amount', 'amplitude', 'turnover_rate']
                for col in numeric_columns:
                    if col in df.columns:
                        df[col] = pd.to_numeric(df[col], errors='coerce')

                return df[required_columns]

            return pd.DataFrame()

        except Exception as e:
            self.logger.error(f"è·å–dc_dailyå¤±è´¥: {e}")
            return pd.DataFrame()

    def get_dc_member(self, trade_date=None, ts_code=None):
        """ä¸œæ–¹è´¢å¯Œæ¿å—æˆåˆ†è‚¡ - åŒ¹é…æ–°è¡¨ç»“æ„"""
        try:
            if not trade_date:
                trade_date = DateUtility.today()

            self.logger.info(f"è·å–ä¸œæ–¹è´¢å¯Œæ¿å—æˆåˆ† {trade_date} {ts_code or ''}")

            params = {'trade_date': trade_date}
            if ts_code:
                params['ts_code'] = ts_code

            df = self._safe_api_call(self.pro.dc_member, **params)
            time.sleep(self.api_delay['member'])

            if df is not None and not df.empty:
                # æ·»åŠ æ—¥æœŸç»´åº¦
                df['ymd'] = trade_date

                # è·å–æ¿å—åç§°ä¿¡æ¯
                if 'ts_code' in df.columns:
                    df['board_name'] = df['ts_code']  # ä¸´æ—¶ç”¨ä»£ç ä»£æ›¿

                # é‡å‘½ååˆ—ä»¥åŒ¹é…æ–°è¡¨ç»“æ„
                df = df.rename(columns={
                    'trade_date': 'ymd',
                    'ts_code': 'board_code',
                    'con_code': 'stock_code',
                    'name': 'stock_name'
                })

                # ç¡®ä¿æ‰€æœ‰å¿…éœ€çš„åˆ—éƒ½å­˜åœ¨
                required_columns = ['ymd', 'board_name', 'board_code', 'stock_code', 'stock_name']

                for col in required_columns:
                    if col not in df.columns:
                        df[col] = None

                return df[required_columns]

            return pd.DataFrame()

        except Exception as e:
            self.logger.error(f"è·å–dc_memberå¤±è´¥: {e}")
            return pd.DataFrame()

    # ============ æ‰¹é‡è·å–å‡½æ•° ============

    def batch_get_all_ths_members(self, board_codes=None, batch_size=5, max_boards=None):
        """
        æ‰¹é‡è·å–æ‰€æœ‰åŒèŠ±é¡ºæ¿å—çš„æˆåˆ†è‚¡
        """
        try:
            if board_codes is None:
                index_df = self.get_ths_index()
                if index_df.empty:
                    self.logger.error("æ— æ³•è·å–æ¿å—åˆ—è¡¨")
                    return pd.DataFrame()
                board_codes = index_df['board_code'].tolist()

            if max_boards:
                board_codes = board_codes[:max_boards]

            total_boards = len(board_codes)
            self.logger.info(f"æ‰¹é‡è·å–{total_boards}ä¸ªæ¿å—çš„æˆåˆ†è‚¡ï¼Œæ‰¹æ¬¡å¤§å°{batch_size}")

            all_members = []

            for i in range(0, total_boards, batch_size):
                batch = board_codes[i:i + batch_size]
                batch_num = i // batch_size + 1
                total_batches = (total_boards + batch_size - 1) // batch_size

                self.logger.info(f"å¤„ç†æ‰¹æ¬¡ {batch_num}/{total_batches}")

                batch_results = []
                for board_code in tqdm(batch, desc=f"æ‰¹æ¬¡{batch_num}"):
                    try:
                        df = self.get_ths_member(board_code)
                        if not df.empty:
                            batch_results.append(df)
                    except Exception as e:
                        self.logger.warning(f"æ¿å— {board_code} å¤±è´¥: {str(e)[:50]}")

                    time.sleep(0.3)

                if batch_results:
                    batch_df = pd.concat(batch_results, ignore_index=True)
                    all_members.append(batch_df)

                    # å®æ—¶ä¿å­˜ - ä½¿ç”¨æ–°è¡¨å
                    self._save_to_mysql(batch_df, "ods_tushare_stock_board_concept_maps_ths",
                                        ['ymd', 'board_code', 'stock_code'])

                # æ‰¹æ¬¡é—´å»¶è¿Ÿ
                if i + batch_size < total_boards:
                    time.sleep(self.api_delay['batch'])

            if all_members:
                final_df = pd.concat(all_members, ignore_index=True)
                self.logger.info(f"æ‰¹é‡è·å–å®Œæˆ: {len(final_df)}æ¡æˆåˆ†è‚¡è®°å½•")
                return final_df

            return pd.DataFrame()

        except Exception as e:
            self.logger.error(f"æ‰¹é‡è·å–æˆåˆ†è‚¡å¤±è´¥: {e}")
            return pd.DataFrame()

    # ============ æ•°æ®ä¿å­˜å‡½æ•° ============

    def _save_to_mysql(self, df, table_name, merge_on):
        """ä¿å­˜æ•°æ®åˆ°MySQL"""
        if df.empty:
            return

        try:
            # è½¬æ¢æ—¥æœŸæ ¼å¼ä¸ºMySQL DATEç±»å‹
            if 'ymd' in df.columns:
                # ç¡®ä¿ymdæ˜¯YYYYMMDDæ ¼å¼çš„å­—ç¬¦ä¸²
                df['ymd'] = pd.to_datetime(df['ymd'], format='%Y%m%d', errors='coerce').dt.strftime('%Y-%m-%d')

            df = df.drop_duplicates(subset=merge_on, keep='first')

            mysql_utils.data_from_dataframe_to_mysql(
                user=base_properties.origin_mysql_user,
                password=base_properties.origin_mysql_password,
                host=base_properties.origin_mysql_host,
                database=base_properties.origin_mysql_database,
                df=df,
                table_name=table_name,
                merge_on=merge_on
            )
            self.logger.info(f"ä¿å­˜æˆåŠŸ: {len(df)}æ¡ -> {table_name}")
        except Exception as e:
            self.logger.error(f"ä¿å­˜åˆ°MySQLå¤±è´¥({table_name}): {e}")

    # ============ å®Œæ•´æ‰§è¡Œå‡½æ•° ============

    def run_all_data_tasks(self, include_kline=True, include_board_members=True,
                           max_ths_boards=50, max_dc_boards=30):
        """
        æ‰§è¡Œæ‰€æœ‰æ•°æ®è·å–ä»»åŠ¡ - åŒ¹é…æ–°è¡¨ç»“æ„
        :param include_kline: æ˜¯å¦åŒ…å«Kçº¿æ•°æ®
        :param include_board_members: æ˜¯å¦åŒ…å«æ¿å—æˆåˆ†è‚¡
        :param max_ths_boards: æœ€å¤§åŒèŠ±é¡ºæ¿å—æ•°
        :param max_dc_boards: æœ€å¤§ä¸œæ–¹è´¢å¯Œæ¿å—æ•°
        :return: ç»“æœç»Ÿè®¡
        """
        self.logger.info("=" * 70)
        self.logger.info("Tushareæ•°æ®ä¸‹è½½ä»»åŠ¡ - åŒ¹é…æ–°è¡¨ç»“æ„ï¼ˆKçº¿è¡¨åä¿æŒä¸å˜ï¼‰")
        self.logger.info("=" * 70)

        results = {}
        today = DateUtility.today()

        # ===== 1. è‚¡ç¥¨æ—¥Kçº¿æ•°æ® =====
        if include_kline:
            self.logger.info("\n1. ä¸‹è½½è‚¡ç¥¨æ—¥Kçº¿æ•°æ®")
            kline_success = self.save_kline_to_mysql()
            results['kline'] = kline_success

        # ===== 2. æ¿å—æ•°æ® =====
        self.logger.info("\n2. ä¸‹è½½æ¿å—æ•°æ®")

        # 2.1 åŒèŠ±é¡ºæ•°æ®
        self.logger.info("  â†’ åŒèŠ±é¡ºæ¿å—æ•°æ®")

        # æ¿å—æŒ‡æ•°åˆ—è¡¨ - æ–°è¡¨å
        ths_index_df = self.get_ths_index()
        if not ths_index_df.empty:
            self._save_to_mysql(ths_index_df, "ods_tushare_board_concept_name_ths",
                                ['ymd', 'board_code'])
            results['ths_index'] = len(ths_index_df)

        # æ¿å—è¡Œæƒ… - æ–°è¡¨å
        ths_daily_df = self.get_ths_daily(limit_days=7)
        if not ths_daily_df.empty:
            self._save_to_mysql(ths_daily_df, "ods_tushare_stock_board_concept_hist_ths",
                                ['ymd', 'board_code'])
            results['ths_daily'] = len(ths_daily_df)

        # æ¿å—æˆåˆ†è‚¡ï¼ˆæ ¸å¿ƒï¼‰ - æ–°è¡¨å
        if include_board_members and not ths_index_df.empty:
            board_codes = ths_index_df['board_code'].tolist()
            if max_ths_boards:
                board_codes = board_codes[:max_ths_boards]

            ths_members_df = self.batch_get_all_ths_members(board_codes, batch_size=5)
            if not ths_members_df.empty:
                results['ths_member'] = len(ths_members_df)

        # 2.2 ä¸œæ–¹è´¢å¯Œæ•°æ®
        self.logger.info("  â†’ ä¸œæ–¹è´¢å¯Œæ¿å—æ•°æ®")

        # æ¦‚å¿µæ¿å— - æ–°è¡¨å
        dc_index_df = self.get_dc_index(today)
        if not dc_index_df.empty:
            self._save_to_mysql(dc_index_df, "ods_tushare_stock_board_concept_name_em",
                                ['ymd', 'board_code'])
            results['dc_index'] = len(dc_index_df)

        # æ¿å—è¡Œæƒ… - æ–°è¡¨å
        dc_daily_df = self.get_dc_daily(today)
        if not dc_daily_df.empty:
            self._save_to_mysql(dc_daily_df, "ods_tushare_stock_board_concept_hist_em",
                                ['ymd', 'board_code'])
            results['dc_daily'] = len(dc_daily_df)

        # æ¿å—æˆåˆ†è‚¡ - æ–°è¡¨å
        if include_board_members:
            dc_member_df = self.get_dc_member(today)
            if not dc_member_df.empty:
                self._save_to_mysql(dc_member_df, "ods_tushare_stock_board_concept_maps_em",
                                    ['ymd', 'board_code', 'stock_code'])
                results['dc_member'] = len(dc_member_df)

        # ===== 3. ä»»åŠ¡å®Œæˆ =====
        self.logger.info("\n" + "=" * 70)
        self.logger.info("ğŸ‰ æ‰€æœ‰æ•°æ®ä¸‹è½½ä»»åŠ¡å®Œæˆï¼")
        self.logger.info("=" * 70)

        # æ±‡æ€»ç»Ÿè®¡
        self.logger.info("ğŸ“Š æ•°æ®ä¸‹è½½ç»Ÿè®¡:")
        for key, value in results.items():
            if key == 'kline':
                status = "æˆåŠŸ" if value else "å¤±è´¥"
                self.logger.info(f"  {key}: {status}")
            else:
                self.logger.info(f"  {key}: {value:,} æ¡")

        return results


def main():
    """ä¸»å‡½æ•° - ç®€æ´ç‰ˆ"""
    print("=" * 60)
    print("Tushareæ•°æ®ä¸‹è½½å™¨ - åŒ¹é…æ–°è¡¨ç»“æ„ï¼ˆKçº¿è¡¨åä¿æŒä¸å˜ï¼‰")
    print("=" * 60)

    # åˆ›å»ºä¸‹è½½å™¨
    token = base_properties.ts_token

    # åˆ›å»ºTushareå®ä¾‹å¹¶è¿›è¡Œè‡ªå®šä¹‰é…ç½®
    ts.set_token(token)
    pro = ts.pro_api()

    # è®¾ç½®è‡ªå®šä¹‰APIä»£ç†
    pro._DataApi__token = token
    pro._DataApi__http_url = 'http://lianghua.nanyangqiankun.top'

    # åˆ›å»ºä¸‹è½½å™¨ï¼Œä¼ å…¥é…ç½®å¥½çš„proå®ä¾‹
    fetcher = TushareDataFetcher(stock_code_df=None)
    fetcher.pro = pro

    # ç®€å•é€‰æ‹©
    print("\nè¯·é€‰æ‹©ä¸‹è½½æ¨¡å¼ï¼š")
    print("1. æ—¥Kçº¿æ•°æ® + æ¿å—æ•°æ®ï¼ˆå…¨éƒ¨ï¼‰")
    print("2. åªä¸‹è½½æ¿å—æ•°æ®ï¼ˆä¸å«Kçº¿ï¼‰")

    choice = input("\nè¯·è¾“å…¥é€‰æ‹© (1/2): ").strip()

    if choice == '1':
        # æ¨¡å¼1ï¼šåŒ…å«Kçº¿
        print("\nğŸ“Š å¼€å§‹ä¸‹è½½ï¼šæ—¥Kçº¿ + å…¨éƒ¨æ¿å—æ•°æ®")
        results = fetcher.run_all_data_tasks(
            include_kline=True,
            include_board_members=True,
            max_ths_boards=50,
            max_dc_boards=30
        )
    elif choice == '2':
        # æ¨¡å¼2ï¼šåªä¸‹è½½æ¿å—
        print("\nğŸ“¦ å¼€å§‹ä¸‹è½½ï¼šä»…æ¿å—æ•°æ®ï¼ˆä¸å«Kçº¿ï¼‰")
        results = fetcher.run_all_data_tasks(
            include_kline=False,
            include_board_members=True,
            max_ths_boards=50,
            max_dc_boards=30
        )
    else:
        print("æ— æ•ˆé€‰æ‹©ï¼Œé€€å‡º")
        return

    print(f"\nâœ… ä¸‹è½½ä»»åŠ¡å®Œæˆï¼")


if __name__ == '__main__':
    main()
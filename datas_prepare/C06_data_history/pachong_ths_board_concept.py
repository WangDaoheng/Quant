import pandas as pd
import requests
import time
import random
from typing import List, Dict
from bs4 import BeautifulSoup
from datetime import datetime
import logging

# å¯¼å…¥ä½ çš„é…ç½®
import CommonProperties.Base_Properties as base_properties
import CommonProperties.Mysql_Utils as mysql_utils
from CommonProperties.DateUtility import DateUtility


class THSConceptCrawler:
    """åŒèŠ±é¡ºæ¦‚å¿µæ¿å—çˆ¬è™« - ä¿®å¤åˆ†é¡µé—®é¢˜"""

    def __init__(self):
        # MySQLé…ç½®
        self.mysql_config = {
            'user': base_properties.origin_mysql_user,
            'password': base_properties.origin_mysql_password,
            'host': base_properties.origin_mysql_host,
            'database': base_properties.origin_mysql_database
        }

        # å®‰å…¨é…ç½®
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
            'DNT': '1',
            'Connection': 'keep-alive',
            'Referer': 'https://q.10jqka.com.cn/',
        })

        # å»¶è¿Ÿé…ç½®
        self.page_delay = 5.0  # é¡µé—´å»¶è¿Ÿ
        self.concept_delay = 8.0  # æ¦‚å¿µé—´å»¶è¿Ÿ
        self.batch_delay = 25.0  # æ‰¹æ¬¡é—´å»¶è¿Ÿ

        # ç®€æ´æ—¥å¿—
        logging.basicConfig(
            level=logging.INFO,
            format='%(message)s'
        )

    def run(self, batch_size: int = 15, test_mode: bool = False):
        """ä¸»æ‰§è¡Œå‡½æ•°"""
        print("=" * 70)
        print("åŒèŠ±é¡ºæ¦‚å¿µæ¿å—è‚¡ç¥¨çˆ¬è™« - ä¿®å¤åˆ†é¡µç‰ˆ")
        print(f"å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("=" * 70)

        # 1. è·å–æ¦‚å¿µæ¿å—
        print("è·å–æ¦‚å¿µæ¿å—æ•°æ®...")
        concepts_df = self._get_concepts()

        if concepts_df.empty:
            print("âŒ æœªè·å–åˆ°æ¦‚å¿µæ¿å—æ•°æ®")
            return

        if test_mode:
            concepts_df = concepts_df.head(3)  # æµ‹è¯•æ¨¡å¼

        total_concepts = len(concepts_df)
        print(f"ğŸ“‹ å…± {total_concepts} ä¸ªæ¦‚å¿µæ¿å—")

        # 2. åˆ†æ‰¹å¤„ç†
        all_success = 0
        total_records = 0

        for batch_idx, batch_start in enumerate(range(0, total_concepts, batch_size), 1):
            batch_end = min(batch_start + batch_size, total_concepts)
            batch = concepts_df.iloc[batch_start:batch_end]

            print(f"\nğŸ“¦ æ‰¹æ¬¡ {batch_idx} - æ¦‚å¿µ {batch_start + 1} åˆ° {batch_end}")

            batch_data = []
            batch_success = 0

            for idx, (_, row) in enumerate(batch.iterrows(), 1):
                code = row['board_code']
                name = row['board_name']

                # æ¦‚å¿µé—´å»¶è¿Ÿ
                if idx > 1:
                    delay = self.concept_delay * random.uniform(0.9, 1.1)
                    time.sleep(delay)

                try:
                    stocks = self._crawl_concept_all_pages(code, name)

                    if stocks:
                        batch_data.extend(stocks)
                        batch_success += 1
                        all_success += 1
                        total_records += len(stocks)
                        print(f"  âœ“ {name[:18]:18s} ({code}): {len(stocks):4d} åª")
                    else:
                        print(f"  - {name[:18]:18s} ({code}): æ— æ•°æ®")

                except Exception as e:
                    print(f"  âœ— {name[:18]:18s} ({code}): é”™è¯¯ - {str(e)[:30]}")
                    time.sleep(10)

            # 3. å†™å…¥å½“å‰æ‰¹æ¬¡æ•°æ®
            if batch_data:
                self._save_batch_to_mysql(batch_data)
                print(f"  ğŸ’¾ æ‰¹æ¬¡å†™å…¥: {len(batch_data):,} æ¡è®°å½•")

            # 4. æ‰¹æ¬¡ç»Ÿè®¡
            print(f"  ğŸ“Š æ‰¹æ¬¡å®Œæˆ: {batch_success}/{len(batch)} ä¸ªæ¦‚å¿µ")
            print(f"  ğŸ“ˆ ç´¯è®¡è¿›åº¦: {all_success}/{total_concepts} ä¸ªæ¦‚å¿µ | {total_records:,} æ¡è®°å½•")

            # 5. æ‰¹æ¬¡é—´å»¶è¿Ÿ
            if batch_end < total_concepts:
                print(f"  â³ æ‰¹æ¬¡é—´éš” {self.batch_delay} ç§’...")
                time.sleep(self.batch_delay)

        # æœ€ç»ˆç»Ÿè®¡
        print("\n" + "=" * 70)
        print("ğŸ‰ çˆ¬å–ä»»åŠ¡å®Œæˆ!")
        print(f"âœ… æˆåŠŸæ¦‚å¿µ: {all_success}/{total_concepts}")
        print(f"ğŸ“Š æ€»è®°å½•æ•°: {total_records:,}")
        print(f"â° ç»“æŸæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

    def _get_concepts(self):
        """ä»MySQLè·å–æ¦‚å¿µæ¿å—"""
        try:
            return mysql_utils.data_from_mysql_to_dataframe_latest(
                user=self.mysql_config['user'],
                password=self.mysql_config['password'],
                host=self.mysql_config['host'],
                database=self.mysql_config['database'],
                table_name="ods_akshare_board_concept_name_ths",
                cols=['board_code', 'board_name']
            )
        except Exception as e:
            print(f"è·å–æ¦‚å¿µæ¿å—å¤±è´¥: {e}")
            return pd.DataFrame()

    def _crawl_concept_all_pages(self, code: str, name: str) -> List[Dict]:
        """çˆ¬å–å•ä¸ªæ¦‚å¿µçš„æ‰€æœ‰é¡µé¢è‚¡ç¥¨"""
        all_stocks = []

        # è·å–æ€»é¡µæ•°
        total_pages = self._get_total_pages(code)
        if total_pages == 0:
            return []

        print(f"    {name[:15]:15s}: å…± {total_pages} é¡µ")

        # é€é¡µçˆ¬å–
        for page in range(1, total_pages + 1):
            # é¡µé—´å»¶è¿Ÿ
            if page > 1:
                delay = self.page_delay * random.uniform(0.8, 1.2)
                time.sleep(delay)

            page_stocks = self._crawl_single_page(code, page)

            if not page_stocks:
                print(f"    ç¬¬ {page} é¡µæ— æ•°æ®ï¼Œåœæ­¢çˆ¬å–")
                break

            # æ ¼å¼åŒ–æ•°æ®
            today = datetime.now().strftime('%Y-%m-%d')
            for stock in page_stocks:
                all_stocks.append({
                    'ymd': today,
                    'board_code': code,
                    'board_name': name,
                    'stock_code': stock.get('ä»£ç ', ''),
                    'stock_name': stock.get('åç§°', '')
                })

            # æ˜¾ç¤ºè¿›åº¦
            if page % 5 == 0 or page == total_pages:
                print(f"    å·²çˆ¬å– {page}/{total_pages} é¡µï¼Œç´¯è®¡ {len(all_stocks)} åªè‚¡ç¥¨")

        return all_stocks

    def _get_total_pages(self, code: str) -> int:
        """å‡†ç¡®è·å–æ€»é¡µæ•° - ä¿®å¤ç‰ˆæœ¬"""
        url = f"https://q.10jqka.com.cn/gn/detail/code/{code}/"

        for attempt in range(3):
            try:
                response = self.session.get(url, timeout=20)
                response.encoding = 'gbk'

                # æ£€æŸ¥é™åˆ¶
                if any(keyword in response.text for keyword in ["è®¿é—®é™åˆ¶", "è¯·ç¨åå†è¯•"]):
                    print(f"    âš ï¸  æ£€æµ‹åˆ°è®¿é—®é™åˆ¶ï¼Œç­‰å¾…20ç§’...")
                    time.sleep(20)
                    continue

                soup = BeautifulSoup(response.text, 'html.parser')

                # æ–¹æ³•1ï¼šæŸ¥æ‰¾åˆ†é¡µä¿¡æ¯ï¼ˆæœ€å¯é ï¼‰
                page_info = soup.find('span', class_='page_info')
                if page_info:
                    text = page_info.get_text(strip=True)
                    if '/' in text:
                        pages = int(text.split('/')[1])
                        return pages

                # æ–¹æ³•2ï¼šæŸ¥æ‰¾æ‰€æœ‰é¡µç é“¾æ¥
                page_links = soup.select('.m-pager a.changePage, .m-pager a[page]')
                max_page = 1
                for link in page_links:
                    try:
                        # ä»hrefæˆ–pageå±æ€§è·å–é¡µç 
                        href = link.get('href', '')
                        page_attr = link.get('page', '')

                        if page_attr and page_attr.isdigit():
                            page_num = int(page_attr)
                        elif '/page/' in href:
                            # ä»URLæå–é¡µç ï¼Œå¦‚ /page/2/
                            parts = href.split('/page/')
                            if len(parts) > 1:
                                page_part = parts[1].split('/')[0]
                                if page_part.isdigit():
                                    page_num = int(page_part)

                        if page_num > max_page:
                            max_page = page_num
                    except:
                        continue

                return max_page

            except Exception as e:
                if attempt < 2:
                    print(f"    è·å–é¡µæ•°å¤±è´¥ç¬¬{attempt + 1}æ¬¡ï¼Œç­‰å¾…10ç§’...")
                    time.sleep(10)
                else:
                    print(f"    æ— æ³•è·å–é¡µæ•°ï¼Œä½¿ç”¨é»˜è®¤1é¡µ")
                    return 1

        return 1

    def _crawl_single_page(self, code: str, page: int) -> List[Dict]:
        """çˆ¬å–å•é¡µè‚¡ç¥¨æ•°æ®"""
        if page == 1:
            url = f"https://q.10jqka.com.cn/gn/detail/code/{code}/"
        else:
            url = f"https://q.10jqka.com.cn/gn/detail/code/{code}/page/{page}/"

        for attempt in range(2):
            try:
                response = self.session.get(url, timeout=15)
                response.encoding = 'gbk'

                if "æš‚æ— æˆä»½è‚¡æ•°æ®" in response.text:
                    return []

                soup = BeautifulSoup(response.text, 'html.parser')

                # æŸ¥æ‰¾è‚¡ç¥¨è¡¨æ ¼
                table = soup.find('table', class_='m-table m-pager-table')
                if not table:
                    # å°è¯•å…¶ä»–å¯èƒ½çš„è¡¨æ ¼ç±»å
                    tables = soup.find_all('table')
                    for t in tables:
                        if 'tbody' in str(t) and 'tr' in str(t):
                            table = t
                            break

                if not table:
                    return []

                stocks = []
                tbody = table.find('tbody')
                if tbody:
                    rows = tbody.find_all('tr')
                    for row in rows:
                        cols = row.find_all('td')
                        if len(cols) >= 3:
                            # æå–è‚¡ç¥¨ä»£ç å’Œåç§°
                            code_elem = cols[1].find('a')
                            name_elem = cols[2].find('a')

                            if code_elem and name_elem:
                                stock_code = code_elem.get_text(strip=True)
                                stock_name = name_elem.get_text(strip=True)

                                # éªŒè¯è‚¡ç¥¨ä»£ç æ ¼å¼
                                if stock_code and len(stock_code) >= 6:
                                    stocks.append({
                                        'ä»£ç ': stock_code,
                                        'åç§°': stock_name
                                    })

                return stocks

            except Exception as e:
                if attempt == 0:
                    print(f"    ç¬¬{page}é¡µè·å–å¤±è´¥ï¼Œé‡è¯•...")
                    time.sleep(8)
                else:
                    return []

        return []

    def _save_batch_to_mysql(self, data: List[Dict]):
        """ä¿å­˜æ‰¹æ¬¡æ•°æ®åˆ°MySQL"""
        if not data:
            return

        try:
            df = pd.DataFrame(data)

            # å»é‡ï¼ˆåŸºäºå…³é”®å­—æ®µï¼‰
            df = df.drop_duplicates(
                subset=['ymd', 'board_code', 'stock_code'],
                keep='first'
            )

            # éªŒè¯æ•°æ®
            print(f"    æ•°æ®éªŒè¯: {len(df)} æ¡ï¼Œå»é‡å {len(df)} æ¡")

            mysql_utils.data_from_dataframe_to_mysql(
                user=self.mysql_config['user'],
                password=self.mysql_config['password'],
                host=self.mysql_config['host'],
                database=self.mysql_config['database'],
                df=df,
                table_name="ods_akshare_stock_board_concept_maps_ths",
                merge_on=['ymd', 'board_code']
            )

            print(f"    âœ… MySQLå†™å…¥æˆåŠŸ")

        except Exception as e:
            print(f"    âš ï¸  å†™å…¥MySQLå¤±è´¥: {e}")
            # ä¿å­˜å¤‡ä»½
            try:
                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                backup_file = f"backup_{timestamp}.parquet"
                df.to_parquet(backup_file, index=False)
                print(f"    æ•°æ®å·²å¤‡ä»½åˆ°: {backup_file}")
            except:
                print("    å¤‡ä»½å¤±è´¥")


def test_single_concept():
    """æµ‹è¯•å•ä¸ªæ¦‚å¿µçš„åˆ†é¡µçˆ¬å–"""
    crawler = THSConceptCrawler()

    # æµ‹è¯•å‡ ä¸ªçƒ­é—¨æ¦‚å¿µ
    test_concepts = [
        ("300008", "æ–°èƒ½æºæ±½è½¦"),  # åº”è¯¥æœ‰å‡ ç™¾åª
        ("301558", "é˜¿é‡Œå·´å·´æ¦‚å¿µ"),  # åº”è¯¥æœ‰å‡ ç™¾åª
        ("301459", "åä¸ºæ¦‚å¿µ"),  # åº”è¯¥æœ‰å‡ ç™¾åª
    ]

    for code, name in test_concepts:
        print(f"\næµ‹è¯•æ¦‚å¿µ: {name} ({code})")
        try:
            stocks = crawler._crawl_concept_all_pages(code, name)
            print(f"  å®é™…è·å–: {len(stocks)} åªè‚¡ç¥¨")

            # æ˜¾ç¤ºå‰5åª
            if stocks:
                print("  ç¤ºä¾‹è‚¡ç¥¨:")
                for i, stock in enumerate(stocks[:5], 1):
                    print(f"    {i}. {stock['stock_code']} {stock['stock_name']}")
        except Exception as e:
            print(f"  é”™è¯¯: {e}")


def main():
    """ä¸»å‡½æ•° - å®Œæ•´çˆ¬å–"""
    crawler = THSConceptCrawler()
    crawler.run(batch_size=10, test_mode=False)


def safe_mode():
    """å®‰å…¨æ¨¡å¼ - æ›´ä¿å®ˆçš„é…ç½®"""
    crawler = THSConceptCrawler()

    # æ›´ä¿å®ˆçš„å»¶è¿Ÿ
    crawler.page_delay = 8.0
    crawler.concept_delay = 12.0
    crawler.batch_delay = 30.0

    print("ğŸ›¡ï¸  å®‰å…¨æ¨¡å¼å¯åŠ¨ï¼ˆä¿å®ˆé…ç½®ï¼‰")
    crawler.run(batch_size=8, test_mode=False)


if __name__ == "__main__":
    print("è¯·é€‰æ‹©è¿è¡Œæ¨¡å¼:")
    print("1. æµ‹è¯•å•ä¸ªæ¦‚å¿µçš„åˆ†é¡µ")
    print("2. å®Œæ•´çˆ¬å–ï¼ˆæ­£å¸¸æ¨¡å¼ï¼‰")
    print("3. å®‰å…¨æ¨¡å¼ï¼ˆæ›´ä¿å®ˆï¼‰")

    choice = input("è¯·è¾“å…¥é€‰æ‹© (1/2/3): ").strip()

    if choice == '1':
        test_single_concept()
    elif choice == '2':
        main()
    elif choice == '3':
        safe_mode()
    else:
        print("æ— æ•ˆé€‰æ‹©ï¼Œä½¿ç”¨æµ‹è¯•æ¨¡å¼")
        test_single_concept()
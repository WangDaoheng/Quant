
from sqlalchemy import create_engine, text
import pymysql
from sqlalchemy.exc import SQLAlchemyError
import gc
from datetime import datetime, timedelta
from typing import List, Optional

import pandas as pd
import numpy as np
import logging
import platform
from sqlalchemy.orm import sessionmaker

import CommonProperties.Base_Properties as base_properties
import CommonProperties.Base_utils as base_utils
from CommonProperties.set_config import setup_logging_config

# è°ƒç”¨æ—¥å¿—é…ç½®   è¿™é‡Œè¦æ³¨é‡Šæ‰ï¼Œä¸ç„¶æ—¥å¿—é‡å¤æ‰“å°
# setup_logging()

###################  mysql é…ç½®   ######################
local_user = base_properties.local_mysql_user
local_password = base_properties.local_mysql_password
local_database = base_properties.local_mysql_database
local_host = base_properties.local_mysql_host

origin_user = base_properties.origin_mysql_user
origin_password = base_properties.origin_mysql_password
origin_database = base_properties.origin_mysql_database
origin_host = base_properties.origin_mysql_host



def check_data_written(total_rows, table_name, engine):
    """
    ç”¨äºæŸ¥è¯¢mysqlå†™å…¥çš„æ•°æ®æ¡æ•°æ˜¯å¦å®Œæ•´
    Args:
        total_rows: è¦éªŒè¯çš„è¡¨çš„ç†è®ºä¸Šçš„è¡Œæ•°
        table_name: è¦éªŒè¯çš„è¡¨çš„åç§°
        engine:     æŸ¥è¯¢å¼•æ“
    Returns:  True æ¡æ•°éªŒè¯åŒ¹é…  / False  æ¡æ•°éªŒè¯ä¸åŒ¹é…
    """

    try:
        # åˆ›å»ºæ•°æ®åº“è¿æ¥
        connection = engine.raw_connection()
        cursor = connection.cursor()

        # æŸ¥è¯¢è¡¨ä¸­å†™å…¥çš„æ•°æ®æ€»æ•°
        check_query = f"SELECT COUNT(*) FROM {table_name}"
        cursor.execute(check_query)
        result = cursor.fetchone()[0]

        # å…³é—­è¿æ¥
        cursor.close()
        connection.close()

        return result == total_rows
    except Exception as e:
        logging.error(f"æ£€æŸ¥æ•°æ®å†™å…¥æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return False


# def data_from_dataframe_to_mysql(user, password, host, database='quant', df=pd.DataFrame(), table_name='', merge_on=[]):
#     """
#     æŠŠ dataframe ç±»å‹æ•°æ®å†™å…¥ mysql è¡¨é‡Œé¢, åŒæ—¶è°ƒç”¨äº†
#     Args:
#         df:
#         table_name:
#         database:
#     Returns:
#     """
#     db_url = f'mysql+pymysql://{user}:{password}@{host}:3306/{database}'
#     engine = create_engine(db_url)
#
#     # å¯¹è¾“å…¥çš„dfçš„ç©ºå€¼åšå¤„ç†
#     # df = df.fillna(value=None)
#     df = df.replace({np.nan: ''})
#
#     # ç¡®ä¿ df ä¸­çš„å­—æ®µåˆ—é¡ºåºä¸è¡¨ä¸­çš„åˆ—é¡ºåºä¸€è‡´
#     columns = df.columns.tolist()
#
#     # æ£€æŸ¥æ˜¯å¦å­˜åœ¨é‡å¤æ•°æ®ï¼Œå¹¶å°†å…¶å»é™¤
#     df.drop_duplicates(subset=merge_on, keep='first', inplace=True)
#
#     total_rows = df.shape[0]
#     if total_rows == 0:
#         logging.info(f"æ‰€æœ‰æ•°æ®å·²å­˜åœ¨ï¼Œæ— éœ€æ’å…¥æ–°çš„æ•°æ®åˆ° {host} çš„ {table_name} è¡¨ä¸­ã€‚")
#         return
#
#     # ä½¿ç”¨ INSERT IGNORE æ¥å»é‡
#     insert_sql = f"""
#     INSERT IGNORE INTO {table_name} ({', '.join(columns)})
#     VALUES ({', '.join(['%s'] * len(columns))});
#     """
#
#     # # è½¬æ¢ df ä¸ºä¸€ä¸ªå¯ä»¥ä¼ é€’ç»™ executemany çš„åˆ—è¡¨
#     # values = df.values.tolist()
#
#     # è½¬æ¢ df ä¸ºä¸€ä¸ªå¯ä»¥ä¼ é€’ç»™ executemany çš„å…ƒç»„åˆ—è¡¨
#     values = [tuple(row) for row in df.to_numpy()]
#
#     with engine.connect() as connection:
#         transaction = connection.begin()
#         try:
#             connection.execute(text(insert_sql), values)
#             transaction.commit()
#             logging.info(f"æˆåŠŸæ’å…¥ {total_rows} è¡Œæ•°æ®åˆ° {host} çš„ {table_name} è¡¨ä¸­ã€‚")
#         except Exception as e:
#             transaction.rollback()
#             logging.error(f"å†™å…¥ {host} çš„è¡¨ï¼š{table_name} æ—¶å‘ç”Ÿé”™è¯¯: {e}")
#             raise

def data_from_dataframe_to_mysql(user, password, host, database='quant', df=pd.DataFrame(), table_name='', merge_on=[]):
    """
    æŠŠ dataframe ç±»å‹æ•°æ®å†™å…¥ mysql è¡¨é‡Œé¢, åŒæ—¶è°ƒç”¨äº†
    Args:
        df:
        table_name:
        database:
    Returns:
    """
    db_url = f'mysql+pymysql://{user}:{password}@{host}:3306/{database}'
    engine = create_engine(db_url)

    # å¯¹è¾“å…¥çš„dfçš„ç©ºå€¼åšå¤„ç†
    df = df.replace({np.nan: None})

    # ç¡®ä¿ df ä¸­çš„å­—æ®µåˆ—é¡ºåºä¸è¡¨ä¸­çš„åˆ—é¡ºåºä¸€è‡´
    columns = df.columns.tolist()

    # æ£€æŸ¥æ˜¯å¦å­˜åœ¨é‡å¤æ•°æ®ï¼Œå¹¶å°†å…¶å»é™¤
    df.drop_duplicates(subset=merge_on, keep='first', inplace=True)

    total_rows = df.shape[0]
    if total_rows == 0:
        logging.info(f"æ‰€æœ‰æ•°æ®å·²å­˜åœ¨ï¼Œæ— éœ€æ’å…¥æ–°çš„æ•°æ®åˆ° {host} çš„ {table_name} è¡¨ä¸­ã€‚")
        return

    # ä½¿ç”¨ INSERT IGNORE æ¥å»é‡
    insert_sql = f"""
    INSERT IGNORE INTO {table_name} ({', '.join(columns)})
    VALUES ({', '.join([f':{col}' for col in columns])});
    """

    # è½¬æ¢ df ä¸ºä¸€ä¸ªå¯ä»¥ä¼ é€’ç»™ executemany çš„å­—å…¸åˆ—è¡¨
    values = df.to_dict('records')

    with engine.connect() as connection:
        transaction = connection.begin()
        try:
            connection.execute(text(insert_sql), values)
            transaction.commit()
            logging.info(f"æˆåŠŸæ’å…¥ {total_rows} è¡Œæ•°æ®åˆ° {host} çš„ {table_name} è¡¨ä¸­ã€‚")
        except Exception as e:
            transaction.rollback()
            logging.error(f"å†™å…¥ {host} çš„è¡¨ï¼š{table_name} æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            raise


def data_from_mysql_to_dataframe(user, password, host, database='quant', table_name='', start_date=None, end_date=None, cols=None):
    """
    ä» MySQL è¡¨ä¸­è¯»å–æ•°æ®åˆ° DataFrameï¼ŒåŒæ—¶è¿›è¡Œæœ€ç»ˆçš„æ•°æ®å®Œæ•´æ€§æ£€æŸ¥å’Œæ—¥å¿—è®°å½•
    Args:
        table_name: MySQL è¡¨å
        database: æ•°æ®åº“åç§°
        start_date: èµ·å§‹æ—¥æœŸ
        end_date: ç»“æŸæ—¥æœŸ
        cols: è¦é€‰æ‹©çš„å­—æ®µåˆ—è¡¨

    Returns:
        df: è¯»å–åˆ°çš„ DataFrame
    """

    db_url = f'mysql+pymysql://{user}:{password}@{host}:3306/{database}'
    engine = create_engine(db_url)

    # æ„å»º SELECT è¯­å¥
    if cols:
        selected_cols = ', '.join(cols)
    else:
        selected_cols = '*'

    # æ„å»º WHERE æ¡ä»¶
    where_conditions = []
    if start_date:
        where_conditions.append(f"ymd >= '{start_date}'")
    if end_date:
        where_conditions.append(f"ymd <= '{end_date}'")

    where_clause = " AND ".join(where_conditions)

    # è¯»å– MySQL è¡¨ä¸­çš„è®°å½•æ€»æ•°
    query_total = f"SELECT COUNT(*) FROM {table_name}"
    if where_clause:
        query_total += f" WHERE {where_clause}"
    total_rows = pd.read_sql(query_total, engine).iloc[0, 0]

    # è¯»å–æ•°æ®çš„æ‰¹é‡å¤§å°
    chunk_size = 10000
    chunks = []

    try:
        for offset in range(0, total_rows, chunk_size):
            query = f"SELECT {selected_cols} FROM {table_name}"
            if where_clause:
                query += f" WHERE {where_clause}"
            query += f" LIMIT {chunk_size} OFFSET {offset}"
            chunk = pd.read_sql(query, engine)
            chunks.append(chunk)

        df = pd.concat(chunks, ignore_index=True)

        # æœ€ç»ˆçš„æ•°æ®å®Œæ•´æ€§æ£€æŸ¥
        if df.shape[0] == total_rows:
            logging.info(f"{host} çš„ mysqlè¡¨ï¼š{table_name} æ•°æ®è¯»å–æˆåŠŸä¸”æ— é—æ¼ï¼Œå…± {total_rows} è¡Œã€‚")
        else:
            logging.warning(f"{table_name} æ•°æ®è¯»å–å¯èƒ½æœ‰é—®é¢˜ï¼Œé¢„æœŸè®°å½•æ•°ä¸º {total_rows}ï¼Œå®é™…è¯»å–è®°å½•æ•°ä¸º {df.shape[0]}ã€‚")

    except Exception as e:
        logging.error(f"ä»è¡¨ï¼š{table_name} è¯»å–æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        df = pd.DataFrame()  # è¿”å›ä¸€ä¸ªç©ºçš„ DataFrame ä»¥é˜²å‡ºé”™æ—¶æ²¡æœ‰è¿”å›æ•°æ®

    return df


def data_from_mysql_to_dataframe_latest(user, password, host, database='quant', table_name='', cols=None):
    """
    ä» MySQL è¡¨ä¸­è¯»å–æœ€æ–°ä¸€å¤©çš„æ•°æ®åˆ° DataFrameï¼ŒåŒæ—¶è¿›è¡Œæœ€ç»ˆçš„æ•°æ®å®Œæ•´æ€§æ£€æŸ¥å’Œæ—¥å¿—è®°å½•
    Args:
        table_name: MySQL è¡¨å
        database: æ•°æ®åº“åç§°
        cols: è¦é€‰æ‹©çš„å­—æ®µåˆ—è¡¨

    Returns:
        df: è¯»å–åˆ°çš„ DataFrame
    """

    db_url = f'mysql+pymysql://{user}:{password}@{host}:3306/{database}'
    engine = create_engine(db_url)

    try:
        # è·å–æœ€æ–°çš„ ymd æ—¥æœŸ
        query_latest_ymd = f"SELECT MAX(ymd) FROM {table_name}"
        latest_ymd = pd.read_sql(query_latest_ymd, engine).iloc[0, 0]

        if latest_ymd is not None:
            # æ„å»º SELECT è¯­å¥
            if cols:
                selected_cols = ', '.join(cols)
            else:
                selected_cols = '*'

            # æŸ¥è¯¢æœ€æ–°ä¸€å¤©çš„æ•°æ®
            query = f"SELECT {selected_cols} FROM {table_name} WHERE ymd = '{latest_ymd}'"
            df = pd.read_sql(query, engine)

            logging.info(f"    mysqlè¡¨ï¼š{table_name} æœ€æ–°ä¸€å¤©({latest_ymd})çš„æ•°æ®è¯»å–æˆåŠŸï¼Œå…± {df.shape[0]} è¡Œã€‚")
        else:
            logging.warning(f"    {table_name} è¡¨ä¸­æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„ ymd æ•°æ®ã€‚")
            df = pd.DataFrame()  # è¿”å›ç©ºçš„ DataFrame

    except Exception as e:
        logging.error(f"    ä»è¡¨ï¼š{table_name} è¯»å–æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        df = pd.DataFrame()  # è¿”å›ä¸€ä¸ªç©ºçš„ DataFrame ä»¥é˜²å‡ºé”™æ—¶æ²¡æœ‰è¿”å›æ•°æ®

    return df


def create_partition_if_not_exists(engine, partition_name, year, month):
    next_month = month + 1
    next_year = year
    if next_month > 12:
        next_month = 1
        next_year += 1

    partition_value = next_year * 100 + next_month

    with engine.connect() as conn:
        query = text(f"""
        ALTER TABLE your_table ADD PARTITION (
            PARTITION {partition_name} VALUES LESS THAN ({partition_value})
        );
        """)
        conn.execute(query)


# def upsert_table(user, password, host, database, source_table, target_table, columns):
#     """
#     ä½¿ç”¨ source_table ä¸­çš„æ•°æ®æ¥æ›´æ–°æˆ–æ’å…¥åˆ° target_table ä¸­ã€‚
#     è¿™æ˜¯ä¸€ç§è¿½åŠ å–å¹¶é›†çš„æ–¹å¼
#
#     :param database:     é»˜è®¤ä¸º quant
#     :param source_table: æºè¡¨åç§°ï¼ˆå­—ç¬¦ä¸²ï¼‰
#     :param target_table: ç›®æ ‡è¡¨åç§°ï¼ˆå­—ç¬¦ä¸²ï¼‰
#     :param columns: éœ€è¦æ›´æ–°æˆ–æ’å…¥çš„åˆ—ååˆ—è¡¨ï¼ˆåˆ—è¡¨ï¼‰
#     """
#
#     db_url = f'mysql+pymysql://{user}:{password}@{host}:3306/{database}'
#     engine = create_engine(db_url)
#
#     # æ„å»ºåˆ—åéƒ¨åˆ†
#     columns_str = ", ".join(columns)
#
#     # æ„å»º ON DUPLICATE KEY UPDATE éƒ¨åˆ†
#     update_str = ", ".join([f"{col} = VALUES({col})" for col in columns])
#
#     # æ„å»º SELECT éƒ¨åˆ†
#     select_str = ", ".join(columns)
#
#     # æ„å»ºå®Œæ•´çš„ SQL è¯­å¥
#     sql = f"""
#     INSERT INTO {target_table} ({columns_str})
#     SELECT {select_str}
#     FROM {source_table}
#     ON DUPLICATE KEY UPDATE
#     {update_str};
#     """
#
#     # æ‰§è¡Œ SQL è¯­å¥
#     with engine.connect() as connection:
#         connection.execute(text(sql))

def upsert_table(
        user: str,
        password: str,
        host: str,
        database: str,
        source_table: str,
        target_table: str,
        columns: List[str],
        unique_key_cols: List[str],  # å¿…é¡»æŒ‡å®šè”åˆå”¯ä¸€é”®å­—æ®µï¼ˆå¦‚ ['htsc_code', 'ymd']ï¼‰
        sync_months: int = 6,  # ä»…ä¿ç•™æ—¶é—´èŒƒå›´é»˜è®¤å€¼ï¼ˆå¯æ‰‹åŠ¨ä¼ å‚è¦†ç›–ï¼‰
        use_ignore: bool = True,  # å†²çªå¿½ç•¥é»˜è®¤å¯ç”¨ï¼ˆå¯æ‰‹åŠ¨å…³é—­ï¼‰
        date_column: str = "ymd"  # æ—¥æœŸç­›é€‰å­—æ®µï¼ˆé»˜è®¤ ymdï¼Œå¯é€‚é…å…¶ä»–æ—¥æœŸå­—æ®µå¦‚ create_timeï¼‰
) -> int:
    """
    é€šç”¨ MySQL upsert å‡½æ•°ï¼šå¢é‡åŒæ­¥æŒ‡å®šæ—¶é—´èŒƒå›´å†…çš„æ•°æ®ï¼Œå†²çªæ—¶ä¸ä¸­æ–­æ‰§è¡Œ
    æ ¸å¿ƒåŠŸèƒ½ï¼šå­˜åœ¨åˆ™æ›´æ–°ï¼Œä¸å­˜åœ¨åˆ™æ’å…¥ï¼›æ”¯æŒä»»æ„è¡¨ã€ä»»æ„è”åˆå”¯ä¸€é”®ã€ä»»æ„å­—æ®µåŒæ­¥

    :param user: æ•°æ®åº“ç”¨æˆ·åï¼ˆå¿…å¡«ï¼‰
    :param password: æ•°æ®åº“å¯†ç ï¼ˆå¿…å¡«ï¼‰
    :param host: æ•°æ®åº“ä¸»æœºIPï¼ˆå¦‚ 192.168.1.100/localhostï¼Œå¿…å¡«ï¼‰
    :param database: æ•°æ®åº“åç§°ï¼ˆå¿…å¡«ï¼‰
    :param source_table: æºè¡¨åç§°ï¼ˆå¿…å¡«ï¼‰
    :param target_table: ç›®æ ‡è¡¨åç§°ï¼ˆå¿…å¡«ï¼‰
    :param columns: åŒæ­¥çš„å­—æ®µåˆ—è¡¨ï¼ˆå¿…å¡«ï¼Œå¦‚ ['col1', 'col2']ï¼‰
    :param unique_key_cols: è”åˆå”¯ä¸€é”®å­—æ®µåˆ—è¡¨ï¼ˆå¿…å¡«ï¼Œå¦‚ ['code', 'date']ï¼Œéœ€ä¸ç›®æ ‡è¡¨å”¯ä¸€çº¦æŸä¸€è‡´ï¼‰
    :param sync_months: åŒæ­¥æ—¶é—´èŒƒå›´ï¼ˆå•ä½ï¼šæœˆï¼Œé»˜è®¤ 6 ä¸ªæœˆï¼Œå¯ä¼ å‚è¦†ç›–ï¼‰
    :param use_ignore: æ˜¯å¦å¿½ç•¥ä¸»é”®å†²çªï¼ˆé»˜è®¤ Trueï¼Œå†²çªæ—¶ç»§ç»­æ‰§è¡Œå…¶ä»–æ•°æ®ï¼‰
    :param date_column: æ—¥æœŸç­›é€‰å­—æ®µåï¼ˆé»˜è®¤ 'ymd'ï¼Œé€‚é…å…¶ä»–æ—¥æœŸå­—æ®µå¦‚ 'create_time'ï¼‰
    :return: å½±å“è¡Œæ•°ï¼ˆæ’å…¥+æ›´æ–°çš„æ€»æ¡æ•°ï¼‰
    """
    # -------------------------- 1. å…¥å‚åˆæ³•æ€§æ ¡éªŒï¼ˆå¿…å¡«é¡¹ä¸èƒ½ä¸ºç©ºï¼‰ --------------------------
    required_params = [
        ("user", user), ("password", password), ("host", host),
        ("database", database), ("source_table", source_table),
        ("target_table", target_table), ("columns", columns),
        ("unique_key_cols", unique_key_cols)
    ]
    for param_name, param_value in required_params:
        if not param_value:
            raise ValueError(f"âŒ å¿…å¡«å‚æ•° '{param_name}' ä¸èƒ½ä¸ºç©º")

    if len(columns) == 0:
        raise ValueError("âŒ åŒæ­¥å­—æ®µåˆ—è¡¨ columns ä¸èƒ½ä¸ºç©º")

    if len(unique_key_cols) == 0:
        raise ValueError("âŒ è”åˆå”¯ä¸€é”®åˆ—è¡¨ unique_key_cols ä¸èƒ½ä¸ºç©º")

    # -------------------------- 2. è®¡ç®—åŒæ­¥æ—¶é—´èŒƒå›´ --------------------------
    current_date = datetime.now()
    start_date = current_date - timedelta(days=sync_months * 30)  # æ¯æœˆæŒ‰30å¤©ç®€åŒ–è®¡ç®—
    start_date_str = start_date.strftime("%Y-%m-%d")
    end_date_str = current_date.strftime("%Y-%m-%d")

    print(f"ğŸ“… åŒæ­¥æ—¶é—´èŒƒå›´ï¼š{start_date_str} è‡³ {end_date_str}ï¼ˆæ—¥æœŸå­—æ®µï¼š{date_column}ï¼‰")
    print(f"ğŸ“¥ æºè¡¨ï¼š{source_table} | ğŸ“¤ ç›®æ ‡è¡¨ï¼š{target_table}")
    print(f"ğŸ” åŒæ­¥å­—æ®µï¼š{', '.join(columns)}")
    print(f"ğŸ”‘ è”åˆå”¯ä¸€é”®ï¼š{', '.join(unique_key_cols)}")

    # -------------------------- 3. å­—æ®µå®‰å…¨æ ¡éªŒï¼ˆé˜² SQL æ³¨å…¥ï¼‰ --------------------------
    def is_valid_field(field: str) -> bool:
        """æ ¡éªŒå­—æ®µåæ˜¯å¦åˆæ³•ï¼ˆä»…å…è®¸å­—æ¯ã€æ•°å­—ã€ä¸‹åˆ’çº¿ï¼Œä¸”ä¸ä»¥æ•°å­—å¼€å¤´ï¼‰"""
        return field.replace('_', '').isalnum() and not field[0].isdigit()

    # è¿‡æ»¤éæ³•å­—æ®µ
    valid_columns = []
    for col in columns:
        if is_valid_field(col):
            valid_columns.append(col)
        else:
            print(f"âš ï¸  å¿½ç•¥éæ³•å­—æ®µåï¼š{col}ï¼ˆä»…å…è®¸å­—æ¯ã€æ•°å­—ã€ä¸‹åˆ’çº¿ï¼Œä¸”ä¸ä»¥æ•°å­—å¼€å¤´ï¼‰")

    valid_unique_keys = []
    for key in unique_key_cols:
        if is_valid_field(key):
            valid_unique_keys.append(key)
        else:
            print(f"âš ï¸  å¿½ç•¥éæ³•å”¯ä¸€é”®å­—æ®µåï¼š{key}ï¼ˆä»…å…è®¸å­—æ¯ã€æ•°å­—ã€ä¸‹åˆ’çº¿ï¼Œä¸”ä¸ä»¥æ•°å­—å¼€å¤´ï¼‰")

    if not valid_columns:
        raise ValueError("âŒ æ— æœ‰æ•ˆåŒæ­¥å­—æ®µï¼Œè¯·æ£€æŸ¥ columns å‚æ•°")
    if not valid_unique_keys:
        raise ValueError("âŒ æ— æœ‰æ•ˆè”åˆå”¯ä¸€é”®å­—æ®µï¼Œè¯·æ£€æŸ¥ unique_key_cols å‚æ•°")

    # -------------------------- 4. æ„å»ºæ•°æ®åº“è¿æ¥ --------------------------
    db_url = f'mysql+pymysql://{user}:{password}@{host}:3306/{database}'
    engine = create_engine(
        db_url,
        charset='utf8mb4',  # æ”¯æŒä¸­æ–‡å’Œç‰¹æ®Šå­—ç¬¦
        pool_pre_ping=True,  # è¿æ¥å‰æ£€æµ‹å­˜æ´»
        pool_size=5,
        max_overflow=10,
        connect_args={
            "options": "--sql_mode=NO_ENGINE_SUBSTITUTION",
            "connect_timeout": 10
        }
    )

    # -------------------------- 5. æ„å»º SQL è¯­å¥ --------------------------
    # ç”¨åå¼•å·åŒ…è£¹è¡¨åå’Œå­—æ®µåï¼Œé¿å…å…³é”®å­—å†²çª
    columns_str = ", ".join([f"`{col}`" for col in valid_columns])
    select_str = columns_str

    # ON DUPLICATE KEY UPDATE éƒ¨åˆ†ï¼ˆä»…æ›´æ–°åŒæ­¥å­—æ®µï¼‰
    update_str = ", ".join([f"`{col}` = VALUES(`{col}`)" for col in valid_columns])

    # æ’å…¥å…³é”®å­—ï¼ˆå†²çªå¿½ç•¥ï¼‰
    insert_keyword = "INSERT IGNORE INTO" if use_ignore else "INSERT INTO"

    # è¿‡æ»¤æ¡ä»¶ï¼šæ—¥æœŸèŒƒå›´ + å”¯ä¸€é”®å­—æ®µéç©ºï¼ˆé¿å…æ— æ•ˆæ•°æ®ï¼‰
    non_null_conditions = " AND ".join([f"`{key}` IS NOT NULL" for key in valid_unique_keys])
    where_clause = f"`{date_column}` >= '{start_date_str}' AND `{date_column}` <= '{end_date_str}' AND {non_null_conditions}"

    # å®Œæ•´ SQL
    sql = f"""
    {insert_keyword} `{target_table}` ({columns_str})
    SELECT {select_str}
    FROM `{source_table}`
    WHERE {where_clause}
    ON DUPLICATE KEY UPDATE {update_str};
    """

    print(f"\nâš™ï¸  æ‰§è¡Œçš„ SQL è¯­å¥ï¼š\n{sql.strip()}")

    # -------------------------- 6. æ‰§è¡Œ SQL å¹¶å¤„ç†ç»“æœ --------------------------
    affected_rows = 0
    try:
        with engine.connect() as connection:
            with connection.begin():  # äº‹åŠ¡æ”¯æŒ
                result = connection.execute(text(sql))
                connection.commit()
                affected_rows = result.rowcount
                print(f"\nâœ… æ‰§è¡ŒæˆåŠŸï¼å½±å“è¡Œæ•°ï¼š{affected_rows}ï¼ˆæ’å…¥+æ›´æ–°ï¼‰")

    except SQLAlchemyError as e:
        error_msg = str(e)
        if "1062 (23000)" in error_msg:
            print(f"\nâš ï¸  è­¦å‘Šï¼šéƒ¨åˆ†æ•°æ®å­˜åœ¨å”¯ä¸€é”®å†²çªï¼ˆå·²è‡ªåŠ¨è·³è¿‡ï¼‰ï¼Œé”™è¯¯æ‘˜è¦ï¼š{error_msg[:500]}")
            affected_rows = 0
        elif "Timeout" in error_msg or "timed out" in error_msg:
            print(f"\nâŒ é”™è¯¯ï¼šæ•°æ®åº“è¿æ¥è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ä¸»æœº IPã€ç«¯å£æ˜¯å¦å¯è¾¾")
            raise
        else:
            print(f"\nâŒ é”™è¯¯ï¼šSQL æ‰§è¡Œå¤±è´¥ï¼Œé”™è¯¯è¯¦æƒ…ï¼š{error_msg[:500]}")
            raise

    except Exception as e:
        print(f"\nâŒ é”™è¯¯ï¼šç¨‹åºæ‰§è¡Œå¤±è´¥ï¼ŒåŸå› ï¼š{str(e)}")
        raise

    finally:
        engine.dispose()
        print(f"\nğŸ”Œ æ•°æ®åº“è¿æ¥å·²å…³é—­")

    return affected_rows




def cross_server_upsert_all(source_user, source_password, source_host, source_database,
                            target_user, target_password, target_host, target_database,
                            source_table, target_table):
    """
    è·¨æœåŠ¡å™¨è¿ç§»æ•°æ®ï¼Œå¹¶åœ¨ç›®æ ‡æœåŠ¡å™¨ä¸Šå®ç°æ•°æ®çš„å¹¶é›†ã€‚
    è¿™æ˜¯ä¸€ç§è¿½åŠ å–å¹¶é›†çš„æ–¹å¼

    :param source_user:      æºæœåŠ¡å™¨çš„æ•°æ®åº“ç”¨æˆ·å
    :param source_password:  æºæœåŠ¡å™¨çš„æ•°æ®åº“å¯†ç 
    :param source_host:      æºæœåŠ¡å™¨çš„ä¸»æœºåœ°å€
    :param source_database:  æºæœåŠ¡å™¨çš„æ•°æ®åº“åç§°
    :param target_user:      ç›®æ ‡æœåŠ¡å™¨çš„æ•°æ®åº“ç”¨æˆ·å
    :param target_password:  ç›®æ ‡æœåŠ¡å™¨çš„æ•°æ®åº“å¯†ç 
    :param target_host:      ç›®æ ‡æœåŠ¡å™¨çš„ä¸»æœºåœ°å€
    :param target_database:  ç›®æ ‡æœåŠ¡å™¨çš„æ•°æ®åº“åç§°
    :param source_table:     æºè¡¨åç§°ï¼ˆå­—ç¬¦ä¸²ï¼‰
    :param target_table:     ç›®æ ‡è¡¨åç§°ï¼ˆå­—ç¬¦ä¸²ï¼‰
    :param columns:          éœ€è¦æ›´æ–°æˆ–æ’å…¥çš„åˆ—ååˆ—è¡¨ï¼ˆåˆ—è¡¨ï¼‰
    """

    # æºæœåŠ¡å™¨è¿æ¥
    source_db_url = f'mysql+pymysql://{source_user}:{source_password}@{source_host}:3306/{source_database}'
    source_engine = create_engine(source_db_url)

    # ç›®æ ‡æœåŠ¡å™¨è¿æ¥
    target_db_url = f'mysql+pymysql://{target_user}:{target_password}@{target_host}:3306/{target_database}'
    target_engine = create_engine(target_db_url)

    # ä»æºæœåŠ¡å™¨è¯»å–æ•°æ®
    df = pd.read_sql_table(source_table, source_engine)

    # åŠ¨æ€è·å–åˆ—å
    columns = df.columns.tolist()

    # åœ¨ç›®æ ‡æœåŠ¡å™¨åˆ›å»ºä¸´æ—¶è¡¨å¹¶æ’å…¥æ•°æ®
    temp_table_name = 'temp_source_data'
    df.to_sql(name=temp_table_name, con=target_engine, if_exists='replace', index=False)

    # æ„å»ºåˆ—åéƒ¨åˆ†
    columns_str = ", ".join(columns)

    # æ„å»º ON DUPLICATE KEY UPDATE éƒ¨åˆ†
    update_str = ", ".join([f"{col} = VALUES({col})" for col in columns])

    # æ„å»º SELECT éƒ¨åˆ†
    select_str = ", ".join(columns)

    # æ„å»ºå®Œæ•´çš„ SQL è¯­å¥
    sql = f"""
    INSERT INTO {target_table} ({columns_str})
    SELECT {select_str}
    FROM {temp_table_name}
    ON DUPLICATE KEY UPDATE 
    {update_str};
    """

    # åœ¨ç›®æ ‡æœåŠ¡å™¨ä¸Šæ‰§è¡Œåˆå¹¶æ“ä½œ
    with target_engine.connect() as connection:
        connection.execute(text(sql))
        connection.execute(f"DROP TABLE {temp_table_name};")

    print(f"æ•°æ®å·²ä» {source_table} è¿ç§»å¹¶åˆå¹¶åˆ° {target_table}ã€‚")



def cross_server_upsert_ymd(source_user, source_password, source_host, source_database,
                            target_user, target_password, target_host, target_database,
                            source_table, target_table, start_date, end_date):
    """
    è·¨æœåŠ¡å™¨è¿ç§»æ•°æ®ï¼Œå¹¶åœ¨ç›®æ ‡æœåŠ¡å™¨ä¸Šå®ç°æ•°æ®çš„å¹¶é›†ã€‚
    è¿™æ˜¯ä¸€ç§è¿½åŠ å–å¹¶é›†çš„æ–¹å¼

    :param source_user:      æºæœåŠ¡å™¨çš„æ•°æ®åº“ç”¨æˆ·å
    :param source_password:  æºæœåŠ¡å™¨çš„æ•°æ®åº“å¯†ç 
    :param source_host:      æºæœåŠ¡å™¨çš„ä¸»æœºåœ°å€
    :param source_database:  æºæœåŠ¡å™¨çš„æ•°æ®åº“åç§°
    :param target_user:      ç›®æ ‡æœåŠ¡å™¨çš„æ•°æ®åº“ç”¨æˆ·å
    :param target_password:  ç›®æ ‡æœåŠ¡å™¨çš„æ•°æ®åº“å¯†ç 
    :param target_host:      ç›®æ ‡æœåŠ¡å™¨çš„ä¸»æœºåœ°å€
    :param target_database:  ç›®æ ‡æœåŠ¡å™¨çš„æ•°æ®åº“åç§°
    :param source_table:     æºè¡¨åç§°ï¼ˆå­—ç¬¦ä¸²ï¼‰
    :param target_table:     ç›®æ ‡è¡¨åç§°ï¼ˆå­—ç¬¦ä¸²ï¼‰
    :param columns:          éœ€è¦æ›´æ–°æˆ–æ’å…¥çš„åˆ—ååˆ—è¡¨ï¼ˆåˆ—è¡¨ï¼‰
    """

    # æºæœåŠ¡å™¨è¿æ¥
    source_db_url = f'mysql+pymysql://{source_user}:{source_password}@{source_host}:3306/{source_database}'
    source_engine = create_engine(source_db_url)

    # ç›®æ ‡æœåŠ¡å™¨è¿æ¥
    target_db_url = f'mysql+pymysql://{target_user}:{target_password}@{target_host}:3306/{target_database}'
    target_engine = create_engine(target_db_url)

    # # ä»æºæœåŠ¡å™¨è¯»å–æ•°æ®
    # df = pd.read_sql_table(source_table, source_engine)

    # ä»æºæœåŠ¡å™¨è¯»å–æ•°æ®ï¼Œé™åˆ¶ ymd åœ¨ [start_date, end_date] å†…
    query = f"""
    SELECT * FROM {source_table}
    WHERE ymd BETWEEN '{start_date}' AND '{end_date}'
    """
    df = pd.read_sql_query(query, source_engine)

    # åŠ¨æ€è·å–åˆ—å
    columns = df.columns.tolist()

    # åœ¨ç›®æ ‡æœåŠ¡å™¨åˆ›å»ºä¸´æ—¶è¡¨å¹¶æ’å…¥æ•°æ®
    temp_table_name = 'temp_source_data'
    df.to_sql(name=temp_table_name, con=target_engine, if_exists='replace', index=False)

    # æ„å»ºåˆ—åéƒ¨åˆ†
    columns_str = ", ".join(columns)
    # æ„å»º ON DUPLICATE KEY UPDATE éƒ¨åˆ†
    update_str = ", ".join([f"{col} = VALUES({col})" for col in columns])
    # æ„å»º SELECT éƒ¨åˆ†
    select_str = ", ".join(columns)

    # æ„å»ºå®Œæ•´çš„ SQL è¯­å¥
    sql = f"""
    INSERT INTO {target_table} ({columns_str})
    SELECT {select_str}
    FROM {temp_table_name}
    ON DUPLICATE KEY UPDATE 
    {update_str};
    """

    # åœ¨ç›®æ ‡æœåŠ¡å™¨ä¸Šæ‰§è¡Œåˆå¹¶æ“ä½œ
    with target_engine.connect() as connection:
        connection.execute(text(sql))
        connection.execute(f"DROP TABLE {temp_table_name};")

    print(f"æ•°æ®å·²ä» {source_table} è¿ç§»å¹¶åˆå¹¶åˆ° {target_table}ã€‚")



def full_replace_migrate(source_host, source_db_url, target_host, target_db_url, table_name, chunk_size=10000):
    """
    å°†æœ¬åœ° MySQL æ•°æ®åº“ä¸­çš„è¡¨æ•°æ®å¯¼å…¥åˆ°è¿œç¨‹ MySQL æ•°æ®åº“ä¸­ã€‚
    æ•´ä½“æš´åŠ›è¿ç§»ï¼Œå…¨åˆ å…¨æ’

    Args:
        source_host   (str): æºç«¯ ä¸»æœº
        source_db_url (str): æºç«¯ MySQL æ•°æ®åº“çš„è¿æ¥ URL
        target_host   (str): ç›®æ ‡ ä¸»æœº
        target_db_url (str): ç›®æ ‡ MySQL æ•°æ®åº“çš„è¿æ¥ URL
        table_name    (str): è¦è¿ç§»çš„è¡¨å
        chunk_size    (int): æ¯æ¬¡è¯»å–å’Œå†™å…¥çš„æ•°æ®å—å¤§å°ï¼Œé»˜è®¤ 10000 è¡Œ
    """
    # åˆ›å»º æºç«¯ æ•°æ®åº“çš„ SQLAlchemy å¼•æ“
    source_engine = create_engine(source_db_url)
    SourceSession = sessionmaker(bind=source_engine)

    # åˆ›å»º ç›®æ ‡ æ•°æ®åº“çš„ SQLAlchemy å¼•æ“
    target_engine = create_engine(target_db_url)
    TargetSession = sessionmaker(bind=target_engine)

    try:
        # æ‰“å¼€æºç«¯å’Œç›®æ ‡ç«¯çš„ä¼šè¯
        with SourceSession() as source_session, TargetSession() as target_session:
            # å¼€å¯äº‹åŠ¡
            with target_session.begin():
                # ç¬¬ä¸€æ¬¡å†™å…¥æ—¶ï¼Œå…ˆæ¸…ç©ºè¡¨
                target_session.execute(text(f"TRUNCATE TABLE {table_name}"))
                print(f"æˆåŠŸæ¸…ç©ºç›®æ ‡è¡¨ {table_name}ã€‚")

            # åˆ†æ‰¹è¯»å–æ•°æ®å¹¶æ’å…¥ç›®æ ‡æ•°æ®åº“
            offset = 0
            while True:
                # ä»æºç«¯æ•°æ®åº“åˆ†æ‰¹è¯»å–æ•°æ®
                query = f"SELECT * FROM {table_name} LIMIT {chunk_size} OFFSET {offset}"
                chunk = pd.read_sql(query, source_session.bind)
                if chunk.empty:
                    break

                # ä½¿ç”¨æ‰¹é‡æ’å…¥
                chunk.to_sql(name=table_name, con=target_engine, if_exists='append', index=False)
                print(f"æˆåŠŸå†™å…¥ç¬¬ {offset // chunk_size + 1} å—æ•°æ®åˆ°{target_host} mysqlåº“ã€‚")

                # æ›´æ–°åç§»é‡
                offset += chunk_size

                # é‡Šæ”¾å†…å­˜
                del chunk
                gc.collect()

        print(f"è¡¨ {table_name} æ•°æ®è¿ç§»å®Œæˆã€‚")

    except Exception as e:
        print(f"æ•°æ®è¿ç§»è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")


def get_stock_codes_latest(df):
    """
    è¿™æ˜¯ä¸ºäº†å–æœ€æ–°çš„ stock_code, é¦–å…ˆé»˜è®¤ä»ç±»å˜é‡é‡Œé¢è·å– stock_code(df), å¦‚æœdfä¸ºç©ºï¼Œå°±ä»mysqlé‡Œé¢å»å–æœ€æ–°çš„
    Args:
        df:
    Returns:
    """

    if df is None or df.empty:

        if platform.system() == "Windows":
            user = local_user
            password = local_password
            host = local_host
            database = local_database
        else:
            user = origin_user
            password = origin_password
            host = origin_host
            database = origin_database

        stock_code_df = data_from_mysql_to_dataframe_latest(user=user,
                                                            password=password,
                                                            host=host,
                                                            database=database,
                                                            table_name='ods_stock_code_daily_insight')

        mysql_stock_code_list = stock_code_df['htsc_code'].tolist()
        logging.info("    ä» æœ¬åœ°Mysqlåº“ é‡Œè¯»å–æœ€æ–°çš„è‚¡ç¥¨ä»£ç ")
    else:
        mysql_stock_code_list = df['htsc_code'].tolist()
        logging.info("    ä» self.stock_code é‡Œè¯»å–æœ€æ–°çš„è‚¡ç¥¨ä»£ç ")

    return mysql_stock_code_list


def execute_sql_statements(user, password, host, database, sql_statements):
    """
    è¿æ¥åˆ°æ•°æ®åº“å¹¶æ‰§è¡Œç»™å®šçš„ SQL è¯­å¥åˆ—è¡¨ã€‚

    å‚æ•°:
    user (str): æ•°æ®åº“ç”¨æˆ·åã€‚
    password (str): æ•°æ®åº“å¯†ç ã€‚
    host (str): æ•°æ®åº“ä¸»æœºåœ°å€ã€‚
    database (str): æ•°æ®åº“åç§°ã€‚
    sql_statements (list): åŒ…å« SQL è¯­å¥çš„åˆ—è¡¨ã€‚
    """
    # åˆ›å»ºæ•°æ®åº“è¿æ¥ URL
    db_url = f'mysql+pymysql://{user}:{password}@{host}:3306/{database}'

    # åˆ›å»ºæ•°æ®åº“å¼•æ“ï¼Œè®¾ç½®è¿æ¥æ± 
    engine = create_engine(db_url, pool_size=10, max_overflow=20, pool_recycle=3600)

    try:
        # ä½¿ç”¨è¿æ¥æ± æ‰§è¡Œ SQL è¯­å¥
        with engine.connect() as connection:
            transaction = connection.begin()  # å¼€å§‹äº‹åŠ¡
            for statement in sql_statements:
                # ä½¿ç”¨ text() æ¥é˜²æ­¢ SQL æ³¨å…¥
                connection.execute(text(statement))
            transaction.commit()  # æäº¤äº‹åŠ¡

    except SQLAlchemyError as e:
        # æ•è·æ•°æ®åº“ç›¸å…³çš„é”™è¯¯
        print(f"Error executing SQL: {e}")
    finally:
        # ç¡®ä¿è¿æ¥è¢«æ­£ç¡®å…³é—­
        engine.dispose()






















